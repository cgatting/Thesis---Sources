\documentclass[12pt,a4paper]{report}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{csquotes}
\usepackage{array}
\usepackage{footnote}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\onehalfspacing

% Metadata
\newcommand{\StudentName}{[Student Name]}
\newcommand{\StudentID}{[Student ID]}
\newcommand{\CourseCode}{CT6042}
\newcommand{\Assessment}{Assignment 001}

% Header/footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\CourseCode{} -- Secure Software Development}
\lhead{\Assessment}
\rfoot{\thepage}

\begin{document}

% Title
\begin{titlepage}
  \centering
  \vspace*{2cm}
  {\Large\bfseries \CourseCode{} -- Secure Software Development \par}
  \vspace{0.8cm}
  {\huge\bfseries Vulnerability Analysis and Secure Development Framework\par}
  \vspace{0.4cm}
  {\large\bfseries Process-Focused Write-up with Reproducible Demos\par}
  \vspace{1.2cm}
  \vfill

  \textbf{Submission Date:} 5 January 2026
  \vfill
\end{titlepage}

\tableofcontents
\newpage
\input{abbreviations}

\chapter{Abstract}
This report documents a series of intentionally vulnerable micro-systems designed to illustrate five core classes of software error: Server-Side Template Injection (SSTI), Insecure Deserialization, Time-of-Check Time-of-Use (TOCTOU) race conditions, JavaScript Prototype Pollution, and XML External Entity (XXE) processing. Each case is treated as a small scientific study: define the flaw, reproduce exploitation in a controlled environment, implement a mitigation grounded in secure design principles, and verify resilience through repeatable tests. The emphasis is on \emph{process} rather than full code listings. Live demonstrations and README files accompany the submission to enable independent replication. Lessons learned are synthesised into an SDLC-aligned framework and a quantitative risk model to guide prioritisation.

\chapter{Introduction}
\section{Why a Process-Centred Approach Matters}
Modern development pipelines reward fast iteration, continuous deployment, and maximal reuse of components. These incentives can unintentionally privilege velocity over systematic risk reduction. A process-centred approach creates a stable path for improvement: we make vulnerabilities \emph{observable}, we define acceptance criteria for mitigations, and we make the testing repeatable so regressions are caught early. The approach is especially useful for classes of bugs that are easy to reintroduce when teams change frameworks or dependencies.

\section{Objectives}
The objectives are threefold: (i) show, with auditable evidence, that each vulnerability can be exploited in a benign but convincing manner; (ii) implement and defend countermeasures that preserve intended functionality; (iii) translate the case-specific findings into general practices that can be embedded into the organisation’s secure development lifecycle.

\section{Ethics and Containment}
All experiments run on localhost or isolated lab containers. Payloads were designed to be non-destructive: they reveal capability (e.g., arithmetic evaluation in SSTI, entity expansion in XXE, prototype mutation) without exfiltrating sensitive data or elevating privileges. Logs and artefacts are retained as evidence; no production data, accounts, or external hosts are touched.

\chapter{Methodology}
\section{Experimental Pattern}
Each case follows the same pattern: (1) \textbf{Minimal Surface}—construct a smallest-possible program that expresses the behaviour; (2) \textbf{Benign Exploit}—craft inputs that demonstrate the flaw without causing harm; (3) \textbf{Instrumentation}—capture HTTP exchanges, logs, file metadata, and timestamps; (4) \textbf{Mitigation}—apply a principled countermeasure; (5) \textbf{Verification}—re-run exactly the same exploit and record failure modes; (6) \textbf{Acceptance Criteria}—define pass/fail conditions that can live in CI.

\section{Threat Assumptions}
For web cases (SSTI, Deserialization, Prototype Pollution, XXE) we assume an unauthenticated remote client capable of sending crafted requests. For TOCTOU we assume a local unprivileged user with the ability to race file operations. Denial-of-service and privilege-escalation primitives outside the lab are out of scope.

\section{Evidence and Chain of Custody}
Evidence includes: (a) request/response pairs saved as text; (b) server logs with timestamps; (c) filesystem \texttt{stat} outputs where relevant; (d) screenshots of demo UI states for Prototype Pollution. All artefacts are labelled with a test ID and linked to the corresponding README section so a third party can repeat the steps and confirm the same outcomes.

% ================= Added chapter: Background and Related Work =================
\chapter{Background and Related Work}
Security engineering is a socio-technical discipline: vulnerabilities do not arise solely from programming mistakes but from organisational incentives, defaults in frameworks, and the difficulty of testing low-probability failures. Industry bodies such as OWASP popularised taxonomy-driven education (e.g., SSTI, XXE, deserialization), while standards such as Microsoft’s SDL and NIST’s SSDF emphasise shifting security earlier in the lifecycle. In practice, teams succeed when they combine concise patterns (\enquote{never evaluate untrusted templates}, \enquote{no unsafe deserializers}) with tooling that makes the desired behaviour cheaper than the unsafe alternative.

Historically, each class in this report emerged from real-world incidents. Prototype pollution became widely discussed after advisories against popular utility libraries; XXE gained prominence through SAML processing flaws; deserialization RCE has appeared across languages from Java to Python; SSTI arose alongside flexible server-side templating; and TOCTOU has been a staple in OS textbooks for decades. Our work deliberately echoes those contexts but uses \emph{benign} payloads so the educational value remains high while operational risk remains low.

From a pedagogy perspective, live, reproducible labs appear to outperform static checklists for beginner and intermediate engineers. A lab makes risk \emph{observable}: before-and-after artefacts anchor abstract concepts in concrete evidence. This, in turn, fuels better code reviews because engineers have a mental model of exploitation and a shared language to define acceptance criteria.

% ================= Added chapter: Measurement and Evidence Strategy ==========
\chapter{Measurement and Evidence Strategy}
A common critique of security reports is the absence of measurable outcomes. We address this by defining for each vulnerability: (i) an objective \emph{capability indicator} (e.g., \enquote{template evaluation observed} or \enquote{marker file created}), (ii) a \emph{mitigation switch} (configuration or code change), and (iii) a \emph{regression test}. Every demonstration records three classes of evidence:
\begin{itemize}
  \item \textbf{Functional evidence}: concrete request/response pairs and UI states that prove or disprove the capability.
  \item \textbf{System evidence}: logs, stack traces, and resource metadata (e.g., \texttt{stat}) with timestamps and test IDs.
  \item \textbf{Design evidence}: a short rationale explaining why the chosen mitigation blocks the exploit class rather than a single payload.
\end{itemize}
This triad helps separate a \enquote{payload fix} from a \enquote{class fix}. For instance, disabling external entities in the XML parser blocks a \emph{class} of attacks, not just the specific file we referenced. Similarly, operating on file descriptors instead of names addresses TOCTOU as a pattern, not just a particular timing window.

% ==================== Case Studies (original, kept) =========================
\chapter{Case Studies}
\section{Server-Side Template Injection (SSTI)}
\subsection{Problem Characterisation}
Template engines combine presentation with dynamic data. SSTI occurs when untrusted input is evaluated as template code rather than rendered as data. Frequent causes include concatenating user input into template strings, using string-based render APIs, or exposing powerful objects in the template context. The severity depends on the engine: many permit access to the object model, file system helpers, or filters that can be chained into remote code execution.

\subsection{Attacker Workflow}
The attack proceeds in stages. First, a \emph{probe} establishes whether expressions are evaluated—e.g., submitting \verb|{{7*7}}| and observing \verb|49| confirms evaluation. Second, the attacker enumerates safe context objects to understand the engine surface. Third, the attacker attempts constrained data access, such as reading a harmless file that ships with the lab. Each step is documented with the exact request path, input payload, and server response. The live demo includes a small harness that automates these probes and writes a CSV of results.

\subsection{Mitigation and Rationale}
Mitigation centres on strict separation of data and code. We remove string-based render calls in favour of precompiled templates, pass user values through explicit parameters, and enforce escaping filters by default. Where feasible, we reduce the template environment’s capabilities, disabling access to dangerous attributes and constraining filters. Logging is adjusted so failed template evaluations are recorded without exposing stack traces to clients.

\subsection{Verification}
The pre-mitigation probe should return computed results; post-mitigation the literal braces should be shown or the input should be encoded. Acceptance criteria: (i) expression inputs are not evaluated; (ii) legitimate template variables still render; (iii) attempts to access engine internals are denied and logged. The README includes screenshots and response excerpts showing both states.

\section{Insecure Deserialization}
\subsection{Problem Characterisation}
Deserialization flaws arise when applications reconstruct objects from untrusted data. Certain formats (e.g., Python pickle) execute arbitrary code paths during object creation. Convenience often leads teams to use such formats to persist state or transport complex data structures. Without an allowlist or integrity check, an attacker can deliver a payload that executes code on deserialization.

\subsection{Attacker Workflow}
The lab exposes an endpoint that accepts a serialized blob. A benign payload writes a marker file in a temporary directory. The test sequence is: generate payload, send payload, confirm marker file creation, and capture logs. This provides a clear, non-destructive proof that untrusted data influenced program execution. We also include a negative control—sending a malformed blob to show standard error handling separate from the exploit behaviour.

\subsection{Mitigation and Rationale}
We migrate to JSON with explicit schema validation. For cases that require binary efficiency, the design prescribes an allowlist of permissible classes and cryptographic signing of messages to prevent tampering. Deserialization is relocated into a restricted process with minimal privileges and a strict timeout to limit blast radius. Operationally, we add an alert rule for any parsing path that reaches a default or legacy deserializer.

\subsection{Verification}
The exploit payload must fail to produce the marker file; the service should return a deterministic 400-series response with a clear validation message. CI includes unit tests for permitted/forbidden shapes and an integration test that posts the previously successful exploit to confirm regression resistance.

\section{Time-of-Check Time-of-Use (TOCTOU)}
\subsection{Problem Characterisation}
A TOCTOU vulnerability occurs when a program checks a security-relevant property (ownership, permissions, existence) and later uses the resource, assuming the property has not changed. The race window between the check and the use allows a motivated local attacker to swap files or symlinks. Such issues are notoriously intermittent, which is why a lab harness that reliably widens the window is valuable for pedagogy.

\subsection{Attacker Workflow}
The vulnerable script inserts a small sleep between \texttt{stat} and \texttt{open}. An attacker process polls for this window and swaps the filename to a symlink targeting a protected file within a safe test directory. Evidence consists of \texttt{stat} output before and after, the content returned to the victim process, and the timing logs that show the overlap. Multiple runs are used to demonstrate both success cases and near-misses, emphasising the stochastic nature of races.

\subsection{Mitigation and Rationale}
The fix is to operate on an already-open file descriptor—perform \texttt{open} first, immediately followed by \texttt{fstat} on the descriptor, and reject if ownership is unexpected. This collapses the race by checking the exact object that will be read. Where the business flow permits, we also recommend avoiding user-named paths entirely by using securely created temporary files and strong directory permissions.

\subsection{Verification}
Re-running the exploit harness should now fail deterministically: either the \texttt{fstat} ownership check rejects the file or the content is provably from the correct object. The README captures consecutive failed attempts with timestamps and a short explanation of why the mitigation is robust across OS variants.

\section{Prototype Pollution}
\subsection{Problem Characterisation}
Prototype pollution arises in JavaScript when untrusted input can write properties such as \texttt{\_\_proto\_\_}, \texttt{constructor}, or \texttt{prototype} onto objects, thereby mutating shared prototypes and altering behaviour application-wide. It is commonly introduced by naïve deep-merge utilities and by copying request bodies directly into configuration or cache objects without validation. Because many business rules hinge on simple property checks (e.g., \texttt{if (obj.isAdmin)}), a polluted prototype can silently flip logic across unrelated code paths, often without explicit stack traces. In practice, even objects created later (with default literals) may inherit the attacker’s injected fields, turning a localized input-handling mistake into a systemic integrity failure.

\subsection{Attacker Workflow}
The attacker submits JSON like \verb|{ "__proto__": { "isAdmin": true } }| to a vulnerable merge endpoint. Subsequent requests that create plain objects then observe \verb|isAdmin === true| even where not intended. The demo UI prints diagnostic outputs before and after the merge to make the effect visible. We also demonstrate variations using nested keys and constructor-based vectors to show breadth.

\subsection{Mitigation and Rationale}
Mitigations consist of three layers: (1) input sanitation that strips dangerous property names; (2) data structures that are immune to prototype mutation (e.g., \verb|Object.create(null)| for configuration maps); (3) dependency hygiene—use maintained libraries with patched merge functions, and pin versions. We also recommend defensive coding practices: do not trust inherited properties in authorisation checks; prefer \verb|Object.hasOwn| or \verb|hasOwnProperty.call| when reading security-relevant flags.

\subsection{Verification}
Automated tests submit payloads containing the dangerous keys and assert that: (a) application prototypes remain unchanged, (b) newly created objects do not exhibit polluted properties, and (c) authorisation checks rely on own-properties only. The UI demo is re-run to capture screenshots of normalised behaviour.

\section{XML External Entity (XXE)}
\subsection{Problem Characterisation}
XXE emerges when XML parsers are allowed to resolve external entities defined in a document’s DOCTYPE. If enabled, attackers can coerce the parser into including the contents of local files or fetching remote resources. Historically, permissive defaults persisted for compatibility in libraries and standards that pre-date modern threat models.

\subsection{Attacker Workflow}
We submit an XML document that defines an external entity referencing a benign local file created by the lab. The vulnerable parser returns output that clearly includes the referenced content. Inputs, outputs, and parser logs are captured. We also include an entity expansion test to demonstrate how quadratic blowup can manifest as resource exhaustion, then disable this path for safety in subsequent runs.

\subsection{Mitigation and Rationale}
The mitigation has two parts: configure the XML parser to disable external entities and DTDs entirely, and use a hardened parsing library that enforces this by default. Additional controls limit document size, depth, and entity counts to prevent resource attacks. Where integrations require resolving external references, we isolate the resolver in a process with no network or file privileges.

\subsection{Verification}
Post-mitigation, the same XML is rejected with a parse error or returns an output absent of any external content. Unit tests assert that entity declarations trigger errors and that legitimate XML without DTDs continues to parse. Logs are reviewed to ensure no sensitive paths or URIs were touched.

% ================= Added chapter: Operational Pitfalls and Anti-patterns =====
\chapter{Operational Pitfalls and Anti-patterns}
Security fixes often regress when subtle operational realities intervene. We therefore record common failure modes:
\begin{itemize}
  \item \textbf{SSTI}: hotfixes that escape inputs but reintroduce string rendering elsewhere; debug modes that expand template capabilities in production; misconfigured error pages that expose context.
  \item \textbf{Deserialization}: \enquote{temporary} exceptions to allow legacy formats that never get removed; inconsistent signing/verification across services; schema drift that bypasses validation.
  \item \textbf{TOCTOU}: platform differences (Windows symlink policies vs Unix), scheduled tasks with elevated privileges reading user paths, and build scripts that assume atomic moves across filesystems.
  \item \textbf{Prototype Pollution}: new dependencies reintroducing unsafe merge utilities; trusting inherited properties in new code; JSON schema validators that do not forbid prototype keys by default.
  \item \textbf{XXE}: library upgrades that silently flip defaults; third-party integrations that require DTDs; XML-to-object mappers that expand entities before validation.
\end{itemize}
These observations motivate organisational controls—coding standards, dependency policies, and CI tests—that reduce reliance on individual vigilance.

% ================= Added chapter: SDLC Roles and RACI ========================
\chapter{SDLC Integration: Roles and RACI}
To make the practices durable, responsibilities are mapped to roles using a lightweight RACI pattern (Responsible, Accountable, Consulted, Informed). Table~\ref{tab:raci} ties concrete activities to stakeholders.

\begin{table}[h]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Activity} & \textbf{Developers} & \textbf{Security Eng.} & \textbf{Tech Lead} & \textbf{Ops} \\
\midrule
Define schema for external inputs & R/A & C & C & I \\
Configure template engine defaults & R & C & A & I \\
Choose serialization formats & C & R & A & I \\
Harden XML parsers & R & C & A & I \\
Implement atomic file IO helpers & R & C & A & I \\
Set dependency policy (merge utils) & C & R & A & I \\
CI regression tests (PoC replay) & R & C & A & I \\
Runtime alerts (entity, prototype, SSTI) & I & C & A & R \\
Security training and playbooks & I & R & A & C \\
\bottomrule
\end{tabular}
\caption{RACI mapping for key controls. R=Responsible, A=Accountable, C=Consulted, I=Informed.}
\label{tab:raci}
\end{table}


This explicit mapping prevents \enquote{security by best effort}. For example, developers are \emph{responsible} for schema definitions because they own the domain model, while security engineers are \emph{accountable} for the policy that JSON, not unsafe binary formats, is used for external interfaces.

% ================= Added chapter: Synthesis and SDLC (kept + expanded) =====
\chapter{Synthesis: From Case Studies to SDLC}
\section{Requirements and Threat Modelling}
Translate the five classes into concrete requirements: \emph{Templates must not evaluate untrusted input}; \emph{No unsafe deserializers are permitted in external interfaces}; \emph{File operations must be atomic with descriptor-based checks}; \emph{No unvetted merges of untrusted objects into global state}; \emph{XML parsers must disable DTD and external entities}. Each requirement is paired with an abuse case and acceptance tests. Threat models are updated to reflect attacker capabilities relevant to each interface.

\section{Design-Time Patterns}
At design time, select libraries and frameworks with defendable defaults: template engines with strict escaping, serializers with schema enforcement, and XML libraries with hardened defaults. Design the file IO boundary to avoid user-controlled paths and to rely on secure temp file APIs. For JavaScript services, plan for prototype-immune data structures and scrutinise any merging utilities.

\section{Implementation Practices}
Implementation guidelines include: explicit input schemas, allowlisted types for deserialization, context-escaping in all rendering paths, rejection of dangerous property names, and consistent use of \verb|Object.hasOwn|. Centralise helpers so that safe functions are idiomatic and convenient, thereby reducing the temptation to use unsafe shortcuts.

\section{Testing Strategy and CI Integration}
Security tests are first-class citizens in CI: unit tests for validators, integration tests that replay PoC payloads, and regression tests pinning previously fixed behaviours. Dependency scanning and Software Bill of Materials (SBOM) tooling are added to detect vulnerable transitive dependencies (especially relevant for JavaScript merge utilities).

\section{Deployment and Monitoring}
Runtime policies enforce least privilege: deserialization runs in restricted sandboxes, services bind to localhost in development by default, and filesystem permissions are minimised. Monitoring emits structured security events—for example, rejected XML with DTDs, stripped prototype keys, and failed template evaluations—with alert thresholds to detect probing.

\chapter{Risk Assessment}
\section{Method}
We score each class by Likelihood (1–5) and Impact (1–5). Likelihood considers prevalence of the pattern in typical stacks and ease of exploitation via simple payloads. Impact considers potential for arbitrary code execution, data disclosure, or global application state corruption.

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Vulnerability} & \textbf{Likelihood} & \textbf{Impact} & \textbf{Risk (L\,\texttimes\,I)} \\
\midrule
Insecure Deserialization & 4 & 5 & 20 \\
SSTI & 3 & 5 & 15 \\
XXE & 3 & 4 & 12 \\
Prototype Pollution & 4 & 3 & 12 \\
TOCTOU & 2 & 4 & 8 \\
\bottomrule
\end{tabular}
\caption{Risk scoring used to prioritise remediation and testing effort.}
\end{table}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.65\textwidth]{risk-heatmap.png}
  \caption{Risk heatmap (Likelihood × Impact) for the five case studies: Insecure Deserialization (20), SSTI (15), XXE (12), Prototype Pollution (12), TOCTOU (8).}
  \label{fig:risk-heatmap}
\end{figure}


\section{Narrative Justification}
\textbf{Insecure Deserialization} scores highest because common runtime libraries accept dangerous formats by default, and exploitation can directly yield code execution. \textbf{SSTI} often reaches code execution depending on engine exposure and thus retains high impact, albeit with slightly lower likelihood in mature frameworks that discourage string-based rendering. \textbf{XXE} remains relevant wherever XML persists in enterprise integrations; hardened defaults lower risk but legacy services keep likelihood moderate. \textbf{Prototype Pollution} has become more salient in modern JavaScript stacks; while impact is highly contextual, its ability to corrupt security checks warrants sustained attention. \textbf{TOCTOU} requires local access and precise timing; although impact can be serious, its operational likelihood is lower in many deployments.

\chapter{Conclusion, Limitations, and Future Directions}
This work has demonstrated five vulnerability classes through controlled, reproducible labs and a process-first lens. The case studies reinforce a common theme: many defects originate from \emph{design shortcuts} and \emph{unsafe defaults}. Reframing security as a repeatable sequence—exploit, mitigate, verify—creates durable guardrails that survive framework changes and team turnover. Embedding those guardrails into requirements, design reviews, shared code libraries, CI tests, deployment checks, and mo nitoring yields cumulative risk reduction without sacrificing delivery velocity.

\section*{Limitations and Threats to Validity}
Our demonstrations prioritise clarity and safety over exploit sophistication. Real attackers may chain multiple primitives, exploit JIT behaviour, or leverage kernel-level features beyond our scope. Reproducibility was assessed on specific runtime and library versions; minor upgrades can alter behaviour. Finally, mitigations can introduce subtle regressions (e.g., over-escaping in templates, schema rigidity that rejects legitimate inputs) and therefore require product-specific tuning and continuous validation.

\section*{Future Directions}
Future work should extend the labs to cloud-native surfaces (message brokers, serverless invocation payloads), container hardening and sandbox escapes, and automated remediation that blocks risky patterns at commit time. Organisationally, the RACI assignments and acceptance criteria presented here can be piloted in a small team, measured for defect escape rate, and then scaled incrementally across services.


\chapter*{Appendix A: Reproduction Guide (Readmes)}
The full codebases are omitted from the main report; however, each demonstration includes a README that enables reproduction:\\[4pt]
\begin{itemize}
  \item \texttt{SSTI-README.md} \;— setup, probes, expected responses, screenshots.
  \item \texttt{Insecure-Deserialization-README.md} \;— payload generation, marker file evidence, negative controls.
  \item \texttt{TOCTOU-README.md} \;— race harness, timing logs, stat outputs.
  \item \texttt{JavaScript-Prototype-Pollution-README.md} \;— UI demo steps, payloads, before/after captures.
  \item \texttt{XXE-README.md} \;— external entity payloads, parser configuration notes, verification tests.
\end{itemize}
These files provide step-by-step commands, environment constraints, and troubleshooting notes. They are intended to be read alongside this process-focused narrative.

\chapter*{Appendix B: Acceptance Criteria (Checklist)}
\begin{enumerate}[label=\arabic*.]
  \item \textbf{SSTI}: expression payloads render literally; logs record denied evaluations; business templates unaffected.
  \item \textbf{Deserialization}: exploit payloads rejected; no marker file creation; schema tests pass in CI.
  \item \textbf{TOCTOU}: race harness fails deterministically; file descriptor checks validated; no symlink traversal.
  \item \textbf{Prototype Pollution}: dangerous keys stripped; prototypes unchanged; authorisation checks use own-properties.
  \item \textbf{XXE}: entity declarations rejected; document limits enforced; legitimate XML still parses.
\end{enumerate}

\end{document}
